{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.tokenizer import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "reviews_data = pd.read_json(r\"C:\\Users\\user\\Documents\\UoM\\Thesis\\data\\Clothing_Shoes_and_Jewelry_5.json\", lines=True)\n",
    "\n",
    "# Keep only the review text and the grade\n",
    "reviews_data = reviews_data[['overall', 'reviewText']]\n",
    "\n",
    "\n",
    "# Drop the products whose values are null\n",
    "reviews_data = reviews_data[reviews_data['reviewText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for index,entry in enumerate(reviews_data['overall']):\n",
    "    if entry == 1.0 or entry == 2.0:\n",
    "        ratings.append(-1)\n",
    "    elif entry == 3.0:\n",
    "        ratings.append(0)\n",
    "    elif entry == 4.0 or entry == 5.0:\n",
    "        ratings.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Split each review into sentences\n",
    "and preprocess each sentence\n",
    "\"\"\"\n",
    "stopwords = stopwords.words('english')\n",
    "lc = LancasterStemmer()\n",
    "\n",
    "preprocessed_data = []\n",
    "index = 0\n",
    "for review in reviews_data['reviewText']:\n",
    "    if(index % 10000 == 0):\n",
    "        print(index)\n",
    "    review_sentences = tokenizer.tokenize(review)\n",
    "    for sentence in review_sentences:\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        sentence = word_tokenize(sentence)\n",
    "        sentence = [lc.stem(word) for word in sentence if not word in stopwords]\n",
    "        sentence = ' '.join(sentence)\n",
    "        if(sentence != ''):\n",
    "            review = {}\n",
    "            review[\"index\"] = index\n",
    "            review[\"sentence\"] = sentence\n",
    "            review[\"rating\"] = ratings[index]\n",
    "            preprocessed_data.append(review)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:  BUCKLE DESIGNI have a variety of these, bought over a span of at least 20 years, and almost certainly made by several different companies. Although the Rothco buckles are \"made in Taiwan\", they are identical (down to the smallest detail) to solid-brass buckles \"made in America\" which I purchased 15 years ago.  Apparently, all buckles of this general type are made to the same government specified design.  These are uniform belts NOT utility belts.  If you want utility belts to hang gear from, consider5.11 TDU 1.5-Inch BeltorUTG Heavy Duty Web Belt - BlackPros/Cons:  I happen to like the precise adjustment, and the ability to wear a belt very loosely when I don't actually need it to hold up my pants---such as when working at my desk. I like being able to adjust the belt on the \"inside\" (where the extra belt material is not visible), so that the end of the belt sticks out only 1\" or so on the outside when worn loosely, and extends to my first belt loop when worn tight.  Tightening such a belt in a hurry (e.g., if you have to stand up and shake a visitors hand) takes just a second and is barely noticeable---particularly compared to the awkward fumbling required to tighten a \"regular\" belt by several notches.  Unfortunately, the belts are not so easy to thread though your belt loops as are slippery leather belts---not normally a problem, however it can be a hassle trying to put your web belt back on after going through airport screening.BUCKLE QUALITYSince these are manufactured by the millions primarily for military use (and to military specifications) they are high quality for the price. The fit and finish of the Rothco \"gold\" and \"silver\" buckles I bought was flawless. No sharp edges, no defects. However, different materials ARE available. The Rothco buckles  are steel, and therefore send metal detectors screaming. Caution: The description of the color \"brass\" means \"gold finish\" NOT solid brass metal construction, similarly \"silver\" means \"white metal\". I have several expensive buckles of the same design in brushed-white and brushed-yellow real solid brass metal, which are NOT detected by airport metal scanners.  Yes I said \"white\" brass---obviously mostly zinc---but called \"white brass\".  Rothco also sells solid brass buckles separately:4406 SOLID BRASS WEB BELT BUCKLE. However, the clip (or clips) on the end (or ends) of these belts are still steel, and will set off metal detectors.\"Setting\" your BeltWhen you \"buckle up, pull the end of the belt to the left with your left hand to adjust the length.  Simultaneously pull the the loose \"gripper pin\" to the right with the thumb and forefinger of your right hand---this sets the gripper tight so that the belt won't accidentally come loose.  After a while it becomes such a habit you don't even think about.SIZEAll are 1 1/4\" wide, the standard size for jeans, chinos, etc.  The size (usually 44\" or 54\") is the length of the web belt, NOT including the buckle and is NOT a waist size. If your waist is >38\", then buy a 54\" belt. Some overlap is necessary. You can choose where you want the overlap---on the outside, say to your first belt loop; or on the inside (where it isn't visible); or both. The belts can easily be shortened (cut to any length you like with scissors), but don't be too quick to shorten the belts---you may need the extra length someday.WEBBING (BELT) QUALITYThe Rothco web belts are thin and rigid, but are just as comfortable as thicker webbing.  Rothco web belts have a clip at only one end (the end which goes through the buckle)---the other end is slightly ragged. Not a problem, but you might want to apply a little glue to the end to prevent fraying.  Elmer's white household glue works well for this purpose.Elmer's All Multipurpose White Glue, 7 5/8 oz. (E379)Apply to the ragged end of the belt, work in, let dry.  Elmer's glue is water soluble and flexible when dry.  I've also used Beacon Fabri-tak which is not water soluble.Beacon Fabri-Tac Permanent Adhesive, 4-Ounce.  It is harder to saturate the fabric with Fabri-tak, but it is particularly good for repairing fraying on old belts.  Fraying (usually after years of use) occurs on the \"business end\" that goes through the buckle.  If you've taken my advice, and have several extra inches on the \"inside\", you can cut off the frayed section and move the clip---or you can move the clip to the opposite end, so that the frayed section is now on the inside.Thin vs Thick & Soft vs Rigid:  On thicker web belts, the clip is sometimes not compressed enough and catches in the buckle--the solution is several whacks with a hammer (cover with a peice of cloth so you don't mar the finish) to close the clip more tightly. It is unlikely that the clips of the thinner Rothco belts will ever catch in the buckles.  Soft belts can \"fall out\" of your first belt loop and flop around.  However, the more rigid Rothco web belts don't flop around, and are unlikely to \"fall out\" of the first belt loop.  In short, the thin rigid webbing is an improvement over the old thicker, softer, webbing.PROBLEM--buckle \"falls off\"Many reviewers report that the buckle \"falls off\" the belt because the gripper (on the back side) doesn't grip well.  Apparently the reason for this is the \"standard\" design, which was originally for the thicker softer belt webbing.  The gripper doesn't grip the thinner harder webbing so tightly.  When you originally setup the belt, pull hard to set the teeth.  Temporarily, you can \"shim\" it up with a scrap of paper,or a short length of Scotch \"invisible\" tape on the buckle under the gripper, for a tighter grip.  Perhaps the best \"shim\" is a 1\" x 1/2\" piece of the sticky part of a \"Post-it\" (stick the sticky side to the back side of the buckle under the gripper)---because it is easy to maneuver into place, and will stay where you put it.  However, even without shimming, after about two weeks of use (without moving the position of the gripper), the gripper will \"set\" and you are unlikely to have problems after that.Why only 4 stars?  Only because I like my solid-brass buckles better---they are undetected by metal detectors and will never rust nor tarnish, and I think that the brushed finish is more attractive than the shiny finish.  Inevitable scratches and abrasions are very obvious on the shiny buckles, but are invisible on the \"brushed\"-finish buckles.\n",
      "------------------------------------------------\n",
      "After preprocessing:  [{'index': 28620, 'sentence': 'buckl design vary bought span least year almost certain mad sev diff company', 'rating': 1}, {'index': 28620, 'sentence': 'although rothco buckl mad taiw id smallest detail solid brass buckl mad americ purchas year ago', 'rating': 1}, {'index': 28620, 'sentence': 'app buckl gen typ mad govern spec design', 'rating': 1}, {'index': 28620, 'sentence': 'uniform belt util belt', 'rating': 1}, {'index': 28620, 'sentence': 'want util belt hang gear consid tdu inch beltorutg heavy duty web belt blackpro con hap lik prec adjust abl wear belt loos act nee hold pant work desk', 'rating': 1}, {'index': 28620, 'sentence': 'lik abl adjust belt insid extr belt mat vis end belt stick outsid worn loos extend first belt loop worn tight', 'rating': 1}, {'index': 28620, 'sentence': 'tight belt hurry e g stand shak visit hand tak second bar not particul comp awkward fumbl requir tight regul belt sev notch', 'rating': 1}, {'index': 28620, 'sentence': 'unfortun belt easy thread though belt loop slippery leath belt norm problem howev hassl try put web belt back going airport screening buckl qualitysint manufact mil prim milit us milit spec high qual pric', 'rating': 1}, {'index': 28620, 'sentence': 'fit fin rothco gold silv buckl bought flawless', 'rating': 1}, {'index': 28620, 'sentence': 'sharp edg defect', 'rating': 1}, {'index': 28620, 'sentence': 'howev diff mat avail', 'rating': 1}, {'index': 28620, 'sentence': 'rothco buckl steel theref send met detect screaming', 'rating': 1}, {'index': 28620, 'sentence': 'caut describ col brass mean gold fin solid brass met construct simil silv mean whit met', 'rating': 1}, {'index': 28620, 'sentence': 'sev expend buckl design brush whit brush yellow real solid brass met detect airport met scan', 'rating': 1}, {'index': 28620, 'sentence': 'ye said whit brass obvy most zint cal whit brass', 'rating': 1}, {'index': 28620, 'sentence': 'rothco also sel solid brass buckl sep solid brass web belt buckl', 'rating': 1}, {'index': 28620, 'sentence': 'howev clip clip end end belt stil steel set met detect', 'rating': 1}, {'index': 28620, 'sentence': 'set beltwh buckl pul end belt left left hand adjust leng', 'rating': 1}, {'index': 28620, 'sentence': 'simult pul loos grip pin right thumb foref right hand set grip tight belt accid com loos', 'rating': 1}, {'index': 28620, 'sentence': 'becom habit ev think sizeal wid standard siz jean chino etc', 'rating': 1}, {'index': 28620, 'sentence': 'siz us leng web belt includ buckl waist siz', 'rating': 1}, {'index': 28620, 'sentence': 'waist buy belt', 'rating': 1}, {'index': 28620, 'sentence': 'overlap necess', 'rating': 1}, {'index': 28620, 'sentence': 'choos want overlap outsid say first belt loop insid vis', 'rating': 1}, {'index': 28620, 'sentence': 'belt easy short cut leng lik sciss quick short belt may nee extr leng someday web belt qualityth rothco web belt thin rigid comfort thick web', 'rating': 1}, {'index': 28620, 'sentence': 'rothco web belt clip on end end goe buckl end slight rag', 'rating': 1}, {'index': 28620, 'sentence': 'problem might want apply littl glu end prev fray', 'rating': 1}, {'index': 28620, 'sentence': 'elm whit household glu work wel purpos elm multipurpos whit glu oz', 'rating': 1}, {'index': 28620, 'sentence': 'e apply rag end belt work let dry', 'rating': 1}, {'index': 28620, 'sentence': 'elm glu wat solubl flex dry', 'rating': 1}, {'index': 28620, 'sentence': 'also us beacon fabr tak wat solubl beacon fabr tac perm adher ount', 'rating': 1}, {'index': 28620, 'sentence': 'hard sat fabr fabr tak particul good repair fray old belt', 'rating': 1}, {'index': 28620, 'sentence': 'fray us year us occ busy end goe buckl', 'rating': 1}, {'index': 28620, 'sentence': 'tak adv sev extr inch insid cut fray sect mov clip mov clip opposit end fray sect insid thin vs thick soft vs rigid thick web belt clip sometim compress enough catch buckl solv sev whack ham cov peic clo mar fin clos clip tight', 'rating': 1}, {'index': 28620, 'sentence': 'unlik clip thin rothco belt ev catch buckl', 'rating': 1}, {'index': 28620, 'sentence': 'soft belt fal first belt loop flop around', 'rating': 1}, {'index': 28620, 'sentence': 'howev rigid rothco web belt flop around unlik fal first belt loop', 'rating': 1}, {'index': 28620, 'sentence': 'short thin rigid web improv old thick soft web problem buckl fal many review report buckl fal belt grip back sid grip wel', 'rating': 1}, {'index': 28620, 'sentence': 'app reason standard design origin thick soft belt web', 'rating': 1}, {'index': 28620, 'sentence': 'grip grip thin hard web tight', 'rating': 1}, {'index': 28620, 'sentence': 'origin setup belt pul hard set tee', 'rating': 1}, {'index': 28620, 'sentence': 'temp shim scrap pap short leng scotch invis tap buckl grip tight grip', 'rating': 1}, {'index': 28620, 'sentence': 'perhap best shim x piec sticky part post stick sticky sid back sid buckl grip easy maneuv plac stay put', 'rating': 1}, {'index': 28620, 'sentence': 'howev ev without shim two week us without mov posit grip grip set unlik problem star', 'rating': 1}, {'index': 28620, 'sentence': 'lik solid brass buckl bet undetect met detect nev rust tarn think brush fin attract shiny fin', 'rating': 1}, {'index': 28620, 'sentence': 'inevit scratches abras obvy shiny buckl invis brush fin buckl', 'rating': 1}]\n",
      "1172750\n"
     ]
    }
   ],
   "source": [
    "print(\"Before preprocessing: \", reviews_data['reviewText'][28620])\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"After preprocessing: \", [d for d in preprocessed_data if d['index'] == 28620])\n",
    "print(len(preprocessed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset into training and test\n",
    "indexes = [i for i in range(len(reviews_data))]\n",
    "\n",
    "Train_X_index, Test_X_index, Train_Y_review, Test_Y_review = model_selection.train_test_split(indexes,ratings,test_size=0.3, random_state=42)\n",
    "\n",
    "df = pd.DataFrame(preprocessed_data)\n",
    "\n",
    "train = df[df['index'].isin(Train_X_index)]\n",
    "Train_Y = train['rating'].tolist()\n",
    "Train_X = train['sentence'].tolist()\n",
    "Train_index = train['index'].tolist()\n",
    "\n",
    "\n",
    "test = df[df['index'].isin(Test_X_index)]\n",
    "Test_Y = test['rating'].tolist()\n",
    "Test_X = test['sentence'].tolist()\n",
    "Test_index = test['index'].tolist()\n",
    "\n",
    "all_sentences = Train_X + Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172750"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of label\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "Train_Y_review = Encoder.fit_transform(Train_Y_review)\n",
    "Test_Y_review = Encoder.fit_transform(Test_Y_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Vectorization\n",
    "        \n",
    "TfIdf_vect = TfidfVectorizer(max_features=10000)\n",
    "TfIdf_vect.fit(all_sentences)\n",
    "Train_X_TfIdf = TfIdf_vect.transform(Train_X)\n",
    "Test_X_TfIdf = TfIdf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling \n",
    "oversample = SMOTE(random_state=100)\n",
    "X_SMOTE, y_SMOTE = oversample.fit_resample(Train_X_TfIdf, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Max_Element(scores):\n",
    "    c = Counter(scores)\n",
    "    negatives = c[0]\n",
    "    neutral = c[1]\n",
    "    positives = c[2]\n",
    "    \n",
    "    if(scores[0] == -1):\n",
    "        negatives += 1\n",
    "    elif(scores[0] == 0):\n",
    "        neutral += 1\n",
    "    elif(scores[0] == 1):\n",
    "        positives += 1\n",
    "    \n",
    "    \n",
    "    if(scores[-1] == -1):\n",
    "        negatives += 1\n",
    "    elif(scores[-1] == 0):\n",
    "        neutral += 1\n",
    "    elif(scores[-1] == 1):\n",
    "        positives += 1\n",
    "\n",
    "    if(neutral == positives and neutral > negatives and positives > negatives):\n",
    "        max_element = 1\n",
    "    elif (neutral == negatives and neutral > positives and negatives > positives):\n",
    "        max_element = 1\n",
    "    elif (neutral == negatives and negatives == positives):\n",
    "        max_element = 1\n",
    "    elif (positives == negatives and positives > neutral and negatives > neutral) :\n",
    "        max_element = 1\n",
    "    else:\n",
    "        max_element = max(set(scores), key = scores.count)\n",
    "        \n",
    "    return max_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9\n",
      "Accuracy:  64.74430288892876\n",
      "----------------------\n",
      "Confusion matrix:  [[ 3513  3707   777]\n",
      " [ 1841  5464  1872]\n",
      " [ 3546 17729 45146]]\n",
      "----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.39      0.44      0.42      7997\n",
      "     Neutral       0.20      0.60      0.30      9177\n",
      "    Positive       0.94      0.68      0.79     66421\n",
      "\n",
      "    accuracy                           0.65     83595\n",
      "   macro avg       0.51      0.57      0.50     83595\n",
      "weighted avg       0.81      0.65      0.70     83595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_SMOTE,y_SMOTE)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB_sentences = Naive.predict(Test_X_TfIdf)\n",
    "\n",
    "# Get grades by review\n",
    "predicted_scores_frame = pd.DataFrame(np.column_stack([Test_index, predictions_NB_sentences, Test_Y]), \n",
    "                               columns=['review Index', 'prediction', 'actual'])\n",
    "\n",
    "print(len(predicted_scores_frame['review Index'].unique()) - len(Test_Y_review))\n",
    "\n",
    "# for each review get all scores by review\n",
    "scores_by_review_frame = predicted_scores_frame.groupby('review Index')['prediction'].apply(list)\n",
    "majority_scores =  scores_by_review_frame.apply(find_Max_Element)\n",
    "predicted_scores = list(majority_scores)\n",
    "\n",
    "# for each review get its actual score\n",
    "actual_scores_frame = predicted_scores_frame.groupby('review Index')['actual'].first()\n",
    "actual_scores = list(actual_scores_frame)\n",
    "\n",
    "# get all indexes\n",
    "review_indexes = predicted_scores_frame['review Index'].unique()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(predicted_scores, actual_scores)*100\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"----------------------\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(actual_scores, predicted_scores)\n",
    "print(\"Confusion matrix: \", cm)\n",
    "print(\"----------------------\")\n",
    "\n",
    "# Classification Report\n",
    "my_tags = ['Negative','Neutral','Positive']\n",
    "report = classification_report(actual_scores, predicted_scores, target_names=my_tags);\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write indexes of false classified reviews to a txt file\n",
    "\n",
    "data = {\"review_index\": review_indexes, \"predict\": predicted_scores, \"actual\": actual_scores}\n",
    "\n",
    "review_dataframe = pd.DataFrame(data)\n",
    "\n",
    "false_classified_indexes = review_dataframe['review_index'][review_dataframe['predict'] != review_dataframe['actual']]\n",
    "false_classified_indexes = list(false_classified_indexes)\n",
    "\n",
    "with open(\"indexes/NaiveBayes_TfIdf_Lancaster.txt\", 'w') as f:\n",
    "    for item in false_classified_indexes:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
