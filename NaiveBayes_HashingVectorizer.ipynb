{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.tokenizer import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "reviews_data = pd.read_json(r\"C:\\Users\\user\\Documents\\UoM\\Thesis\\data\\All_Beauty_5.json\", lines=True)\n",
    "\n",
    "# Keep only the review text and the grade\n",
    "reviews_data = reviews_data[['overall', 'reviewText']]\n",
    "\n",
    "# Drop the products whose values are null\n",
    "reviews_data = reviews_data[reviews_data['reviewText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for index,entry in enumerate(reviews_data['overall']):\n",
    "    if entry == 1.0 or entry == 2.0:\n",
    "        ratings.append(-1)\n",
    "    elif entry == 3.0:\n",
    "        ratings.append(0)\n",
    "    elif entry == 4.0 or entry == 5.0:\n",
    "        ratings.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Split each review into sentences\n",
    "and preprocess each sentence\n",
    "\"\"\"\n",
    "preprocessed_data = []\n",
    "index = 0\n",
    "for review in reviews_data['reviewText']:\n",
    "    # Split each review into sentences\n",
    "    review_sentences = tokenizer.tokenize(review)\n",
    "    for sentence in review_sentences:\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "        sentence = sentence.lower()\n",
    "        sentence = word_tokenize(sentence)\n",
    "        sentence = [word for word in sentence if not word in set(stopwords.words('english'))]\n",
    "        sentence = ' '.join(sentence)\n",
    "        review = {}\n",
    "        review[\"index\"] = index\n",
    "        review[\"sentence\"] = sentence\n",
    "        review[\"rating\"] = ratings[index]\n",
    "        preprocessed_data.append(review)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:  My product was not sealed and either used or something.. attached are pictures. Would like a refund please.\n",
      "------------------------------------------------\n",
      "After preprocessing:  [{'index': 34, 'sentence': 'product sealed either used something attached pictures', 'rating': -1}, {'index': 34, 'sentence': 'would like refund please', 'rating': -1}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before preprocessing: \", reviews_data['reviewText'][34])\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"After preprocessing: \", [d for d in preprocessed_data if d['index'] == 34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset into training and test\n",
    "indexes = [i for i in range(len(reviews_data))]\n",
    "\n",
    "Train_X_index, Test_X_index, Train_Y_review, Test_Y_review = model_selection.train_test_split(indexes,ratings,test_size=0.3)\n",
    "\n",
    "Train_X = [d['sentence'] for d in preprocessed_data if d['index'] in Train_X_index]\n",
    "Train_Y = [d['rating'] for d in preprocessed_data if d['index'] in Train_X_index]\n",
    "Test_X = [d['sentence'] for d in preprocessed_data if d['index'] in Test_X_index]\n",
    "Test_Y = [d['rating'] for d in preprocessed_data if d['index'] in Test_X_index]\n",
    "Train_index = [d['index'] for d in preprocessed_data if d['index'] in Train_X_index]\n",
    "Test_index = [d['index'] for d in preprocessed_data if d['index'] in Test_X_index]\n",
    "\n",
    "all_sentences = Train_X + Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5264"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_data.notna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of label\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "Train_Y_review = Encoder.fit_transform(Train_Y_review)\n",
    "Test_Y_review = Encoder.fit_transform(Test_Y_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Vectorization\n",
    "        \n",
    "Hashing_vect = HashingVectorizer(alternate_sign=False)\n",
    "Hashing_vect.fit(all_sentences)\n",
    "Train_X_Hashing = Hashing_vect.transform(Train_X)\n",
    "Test_X_Hashing = Hashing_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Hashing,Train_Y)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB_sentences = Naive.predict(Test_X_Hashing)\n",
    "\n",
    "# Get grades by review\n",
    "predicted_scores_frame = pd.DataFrame(np.column_stack([Test_index, predictions_NB_sentences]), \n",
    "                               columns=['review Index', 'prediction'])\n",
    "\n",
    "#find the majority score by review\n",
    "reviews_sentiment = []\n",
    "for item in predicted_scores_frame['review Index'].unique():\n",
    "    scores = list(predicted_scores_frame[predicted_scores_frame['review Index'] == item]['prediction'])\n",
    "    majority_score = max(set(scores), key = scores.count)\n",
    "    reviews_sentiment.append(majority_score)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(reviews_sentiment, Test_Y_review)*100\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Test_Y_review, reviews_sentiment)\n",
    "\n",
    "# Classification Report\n",
    "my_tags = ['Negative','Neutral','Positive']\n",
    "report = classification_report(Test_Y_review, reviews_sentiment, target_names=my_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.86075949367088\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
